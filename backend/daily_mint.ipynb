{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9db8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ee0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_helpers import *\n",
    "from web3 import Web3\n",
    "import os, json\n",
    "from supabase import create_client, Client\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d12982",
   "metadata": {},
   "source": [
    "# Nightly Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4afe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {\n",
    "    \"categories\": pd.DataFrame(get_data(\"categories\", \"*\")),\n",
    "    \"comments\": pd.DataFrame(get_data(\"comments\", \"*\")),\n",
    "    \"follows\": pd.DataFrame(get_data(\"follows\", \"*\")),\n",
    "    \"posts\": pd.DataFrame(get_data(\"posts\", \"*\")),\n",
    "    \"users\": pd.DataFrame(get_data(\"users\", \"*\")),\n",
    "    \"votes\": pd.DataFrame(get_data(\"votes\", \"*\")),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98de8b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6056 entries, 0 to 6055\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       6056 non-null   int64  \n",
      " 1   created_at               6056 non-null   object \n",
      " 2   username                 28 non-null     object \n",
      " 3   profile_pic              6056 non-null   object \n",
      " 4   msa_id                   0 non-null      object \n",
      " 5   transaction_hash         0 non-null      object \n",
      " 6   wallet_address_personal  3 non-null      object \n",
      " 7   wallet_address_provided  0 non-null      object \n",
      " 8   exp                      6056 non-null   int64  \n",
      " 9   level                    6056 non-null   int64  \n",
      " 10  reddit_airdrop_value     714 non-null    float64\n",
      " 11  reddit_airdrop_claimed   6056 non-null   object \n",
      " 12  reddit_username          6051 non-null   object \n",
      " 13  github_username          0 non-null      object \n",
      " 14  discord_username         0 non-null      object \n",
      " 15  email                    0 non-null      object \n",
      " 16  daily_payout_claimed     6056 non-null   bool   \n",
      " 17  exp_to_next_level        6056 non-null   float64\n",
      " 18  tokens_to_claim          6056 non-null   int64  \n",
      " 19  tokens_claimed           6056 non-null   bool   \n",
      " 20  daily_payout_value       6056 non-null   float64\n",
      " 21  social_score             6056 non-null   float64\n",
      "dtypes: bool(2), float64(4), int64(4), object(12)\n",
      "memory usage: 958.2+ KB\n"
     ]
    }
   ],
   "source": [
    "all_data['users'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b28101d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['social_score'] = social_score\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['level'] = level\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['overall_score'] = overall_score\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['overall_score'] /= max(overall_score)\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['exp'] = exp\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['exp_to_next_level'] = exp_to_next_level\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['daily_payout_value'] = daily_token_rewards * df['overall_score']\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[df['daily_payout_value'] < 100] = 100\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['social_score'] = social_score\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:143: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['level'] = level\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:144: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['overall_score'] = overall_score\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:145: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['overall_score'] /= max(overall_score)\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['exp'] = exp\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['exp_to_next_level'] = exp_to_next_level\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['daily_payout_value'] = daily_token_rewards * df['overall_score']\n",
      "F:\\web3_messing_around\\PostThread-Polygon\\backend\\db_helpers.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[df['daily_payout_value'] < 100] = 100\n"
     ]
    }
   ],
   "source": [
    "# Daily payout\n",
    "for idx, row in all_data['users'][all_data['users']['daily_payout_claimed'] == True].iterrows():\n",
    "    updates = {\n",
    "        \"daily_payout_claimed\": False, \n",
    "        \"tokens_to_claim\": row['tokens_to_claim'] + row['daily_payout_value']\n",
    "    }\n",
    "    supabase.table(\"users\").update(updates).eq(\"id\", row['id']).execute()\n",
    "    \n",
    "all_users = all_data['users'].copy()\n",
    "all_users.loc[all_users['username'].isna(), :] = update_scores(all_data, all_users[all_users['username'].isna()])\n",
    "all_users.loc[~all_users['username'].isna(), :] = update_scores(all_data, all_users[~all_users['username'].isna()])\n",
    "\n",
    "for idx, row in all_users.iterrows():\n",
    "    updates = {\n",
    "        'social_score': row['social_score'],\n",
    "        'level': row['level'],\n",
    "        'exp': row['exp'],\n",
    "        'exp_to_next_level': row['exp_to_next_level'],\n",
    "        'daily_payout_value': row['daily_payout_value'],\n",
    "    }\n",
    "    supabase.table(\"users\").update(updates).eq(\"id\", row['id']).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e91aa867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done update airdrop value\n"
     ]
    }
   ],
   "source": [
    "# Reddit Airdrop\n",
    "\n",
    "# Update airdrop value\n",
    "for idx, row in all_data['users'][~all_data['users']['reddit_username'].isna() & all_data['users']['reddit_airdrop_value'].isna()  & ~all_data['users']['username'].isna()].iterrows():\n",
    "    user = reddit.redditor(row['reddit_username'])   \n",
    "    try:\n",
    "        airdrop_value = user.total_karma\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    supabase.table(\"users\").update({\"reddit_airdrop_value\": airdrop_value}).eq(\"id\", row['id']).execute()\n",
    "print(\"Done update airdrop value\")\n",
    "                \n",
    "# Check for claims\n",
    "for idx, row in all_data['users'][all_data['users']['reddit_airdrop_claimed'] == \"pending\"].iterrows():\n",
    "    if row['reddit_id'] is None:\n",
    "        supabase.table(\"users\").update({\"reddit_airdrop_claimed\": \"rejected\"}).eq(\"id\", row['id']).execute()\n",
    "    \n",
    "    user = reddit.redditor(reddit_username)  \n",
    "    try:\n",
    "        for i, post in enumerate(user.new()):\n",
    "            if i > 10:\n",
    "                break\n",
    "            if type(post) == praw.models.reddit.submission.Submission:\n",
    "                if row[\"wallet_address_personal\"] in post.selftext:\n",
    "                    airdrop_value = user.total_karma\n",
    "                    updates = {\n",
    "                        \"reddit_airdrop_value\": airdrop_value,\n",
    "                        \"reddit_airdrop_claimed\": \"claimed\",\n",
    "                        \"tokens_to_claim\": row['tokens_to_claim'] + airdrop_value,\n",
    "                    }\n",
    "                    supabase.table(\"users\").update(updates).eq(\"id\", row['id']).execute()\n",
    "    except:\n",
    "        supabase.table(\"users\").update({\"reddit_airdrop_claimed\": \"rejected\"}).eq(\"id\", row['id']).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d57d4b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transfer tokens\n",
    "\n",
    "for idx, row in all_data['users'][(all_data['users']['tokens_claimed'] == True) & (all_data['users']['tokens_to_claim'] != 0) & (~all_data['users']['wallet_address_personal'].isna())].iterrows():\n",
    "    with open(\"new_announcements.txt\", \"a\") as file_object:\n",
    "        file_object.write(json.dumps({\"type\": \"mint_tokens\", \"wallet\": row[\"wallet_address_personal\"], \"amount\": row[\"tokens_to_claim\"]}) + '\\n')\n",
    "    supabase.table(\"users\").update({\"tokens_claimed\": False, \"tokens_to_claim\": 0}).eq(\"id\", row['id']).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bbb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mint users\n",
    "top_users = all_data['users'][!all_data['users']['username'].isna() & all_data['users']['msa_id'].isna()]\n",
    "top_users = top_users.sort_values(\"exp\")\n",
    "\n",
    "for idx, row in top_users.iterrows():\n",
    "    wallet = get_wallet_from_username(row['username'])\n",
    "    with open(\"new_announcements.txt\", \"a\") as file_object:\n",
    "        file_object.write(json.dumps({\"type\": \"new_user\", \"private_key\": wallet.privateKey}) + '\\n')\n",
    "    supabase.table(\"users\").update({\"wallet_address_provided\": wallet.address).eq(\"id\", row['id']).execute()\n",
    "    \n",
    "# Mint users with msa\n",
    "top_users = all_data['users'][!all_data['users']['username'].isna() & all_data['users']['transaction_hash'].isna() & ~all_data['users']['msa_id'].isna()]\n",
    "top_users = top_users.sort_values(\"exp\")\n",
    "\n",
    "for idx, row in top_users.iterrows():\n",
    "    wallet = get_wallet_from_username(row['username'])\n",
    "    message = mint_user(row['msa_id'], row['profile_pic'], wallet.address)\n",
    "    with open(\"new_announcements.txt\", \"a\") as file_object:\n",
    "        file_object.write(json.dumps({\"type\": \"mint_data\", \"message\": message, \"amount\": row[\"msa_id\"]}) + '\\n')\n",
    "    supabase.table(\"users\").update({\"tokens_claimed\": False, \"tokens_to_claim\": 0}).eq(\"id\", row['id']).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mint posts\n",
    "top_posts = all_data['posts'][all_data['posts']['reddit_id'].isna() & all_data['posts']['transaction_hash'].isna() & ~all_data['posts']['ipfs_hash'].isna()]\n",
    "top_posts = top_posts.join(all_data['users'].set_index('id')[['username', 'msa_id', 'tokens_to_claim']], on=\"user_id\")\n",
    "top_posts = top_posts[~top_posts['msa_id'].isna() & ~top_posts['username'].isna() & top_posts['tokens_to_claim'] > 5]\n",
    "top_posts = top_posts.join(all_data['votes'].groupby(\"post_id\").sum()[['up']], on=\"id\", how=\"inner\")\n",
    "top_posts = top_posts.sort_values(\"up\")\n",
    "\n",
    "for idx, row in top_posts.iterrows():\n",
    "    \n",
    "    \n",
    "    with open(\"new_announcements.txt\", \"a\") as file_object:\n",
    "        file_object.write(json.dumps({\"type\": \"mint_tokens\", \"wallet\": row[\"wallet_address_personal\"], \"amount\": row[\"tokens_to_claim\"]}) + '\\n')\n",
    "    \n",
    "    supabase.table(\"users\").update({\"tokens_claimed\": False, \"tokens_to_claim\": 0}).eq(\"id\", row['id']).execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
